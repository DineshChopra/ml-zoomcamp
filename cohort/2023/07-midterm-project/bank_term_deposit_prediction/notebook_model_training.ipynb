{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "927cb03a",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5200c3",
   "metadata": {},
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "89aeef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c008c77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "# Define the input data file and model artifact paths\n",
    "data_file = \"data/Assignment-2_Data.csv\"  \n",
    "artifact_base_path = \"artifacts\"\n",
    "artifact_file = f\"{artifact_base_path}/model.bin\"\n",
    "target = 'y'\n",
    "\n",
    "# List of models with their configurations\n",
    "model_infos = [\n",
    "  {\n",
    "    \"name\": \"LR\",\n",
    "    \"model\": LogisticRegression(),\n",
    "    \"params\": {\n",
    "      \"solver\": ['liblinear'],\n",
    "      \"C\": [1.0],\n",
    "      \"max_iter\": [10, 50, 100]\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"DecisionTreeClassifier\",\n",
    "    \"model\": DecisionTreeClassifier(),\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"RandomForestClassifier\",\n",
    "    \"model\": RandomForestClassifier(),\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"XGBClassifier\",\n",
    "    \"model\": xgb.XGBClassifier(\n",
    "      objective=\"binary:logistic\",  # For binary classification\n",
    "      random_state=42,              # Random seed for reproducibility\n",
    "      n_jobs=-1,                    # Used for parallel processing, It will use all available CPU's\n",
    "      use_label_encoder=False\n",
    "    ),\n",
    "    \"params\": {\n",
    "      \"n_estimators\": [200],         # Number of boosting rounds\n",
    "      \"learning_rate\": [0.1],    # Learning rate\n",
    "      \"max_depth\": [5],                 # Maximum depth of each tree\n",
    "    }\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"LDA\",\n",
    "    \"model\": LinearDiscriminantAnalysis()\n",
    "  },\n",
    "  {\n",
    "    \"name\": \"NB\",\n",
    "    \"model\": GaussianNB()\n",
    "  }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a73b87",
   "metadata": {},
   "source": [
    "## Read Dataset\n",
    "\n",
    "* Read Dataframe by using `pandas`\n",
    "* Remove null values\n",
    "* Remove not required fields\n",
    "* Remove `age` outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fb9a11b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_file):\n",
    "  \"\"\"\n",
    "  Read the input data from a CSV file.\n",
    "\n",
    "  Args:\n",
    "    data_file (str): Path to the input data file.\n",
    "\n",
    "  Returns:\n",
    "    pd.DataFrame: A pandas DataFrame containing the input data.\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(data_file)\n",
    "  df.dropna(inplace=True)\n",
    "  not_required_field = [ \"Id\", \"default\" ]\n",
    "  df.drop(columns=not_required_field, inplace=True)\n",
    "  indexes_to_drop = df[(df['age'] == 999.0) | (df['age'] == -1)].index\n",
    "  df.drop(indexes_to_drop, inplace=True)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "413049ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(\"data/Assignment-2_Data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6638dddc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.0</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>29.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33.0</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>2.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47.0</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1506.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35.0</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>231.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>139</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age           job  marital  education  balance housing loan  contact  day   \n",
       "1  44.0    technician   single  secondary     29.0     yes   no  unknown    5  \\\n",
       "2  33.0  entrepreneur  married  secondary      2.0     yes  yes  unknown    5   \n",
       "3  47.0   blue-collar  married    unknown   1506.0     yes   no  unknown    5   \n",
       "4  33.0       unknown   single    unknown      1.0      no   no  unknown    5   \n",
       "5  35.0    management  married   tertiary    231.0     yes   no  unknown    5   \n",
       "\n",
       "  month  duration  campaign  pdays  previous poutcome   y  \n",
       "1   may       151         1     -1         0  unknown  no  \n",
       "2   may        76         1     -1         0  unknown  no  \n",
       "3   may        92         1     -1         0  unknown  no  \n",
       "4   may       198         1     -1         0  unknown  no  \n",
       "5   may       139         1     -1         0  unknown  no  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3deaa57",
   "metadata": {},
   "source": [
    "## Split Dataframe into `train`, `val` and `test` sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7b86be40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe(df):\n",
    "  \"\"\"\n",
    "  Split the input dataframe into train, validation and test sets\n",
    "  \n",
    "  Args:\n",
    "    df (pd.DataFrame): Input DataFrame.\n",
    "  \n",
    "  Returns:\n",
    "    pd.DataFrame: DataFrames for training, validation, and test sets.\n",
    "  \"\"\"\n",
    "  df[target] = df[target].replace({'yes': 1, 'no': 0})\n",
    "  df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "  df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=42)\n",
    "\n",
    "  df_train = df_train.reset_index(drop=True)\n",
    "  df_val = df_val.reset_index(drop=True)\n",
    "  df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "  y_train = df_train[target].values\n",
    "  y_val = df_val[target].values\n",
    "  y_test = df_test[target].values\n",
    "\n",
    "  del df_train[target]\n",
    "  del df_val[target]\n",
    "  del df_test[target]\n",
    "  return df_train, y_train, df_val, y_val, df_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6f400dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, y_train, df_val, y_val, df_test, y_test = split_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853fb02",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "\n",
    "* Convert dataframe into dict\n",
    "* Apply one hot coding by using  `DictVectorizer`\n",
    "* Apply normalization by using `StandardScaler`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "2ec70cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_data(df_train, df_val, df_test):\n",
    "  \"\"\"\n",
    "  Preprocess the data including one-hot encoding and standardization.\n",
    "\n",
    "  Args:\n",
    "    df_train (pd.DataFrame): Training data.\n",
    "    df_val (pd.DataFrame): Validation data.\n",
    "    df_test (pd.DataFrame): Test data.\n",
    "\n",
    "  Returns:\n",
    "    Tuple: Tuple containing the DictVectorizer, StandardScaler, and preprocessed data.\n",
    "  \"\"\"\n",
    "  dict_train = df_train.to_dict(orient='records')\n",
    "  dict_val = df_val.to_dict(orient='records')\n",
    "  dict_test = df_test.to_dict(orient='records')\n",
    "\n",
    "  dv = DictVectorizer(sparse=False)\n",
    "  X_train = dv.fit_transform(dict_train)\n",
    "  X_val = dv.transform(dict_val)\n",
    "  X_test = dv.transform(dict_test)\n",
    "\n",
    "  scaler = StandardScaler()\n",
    "  X_train = scaler.fit_transform(X_train)\n",
    "  X_val = scaler.transform(X_val)\n",
    "  X_test = scaler.transform(X_test)\n",
    "\n",
    "  return dv, scaler, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d098175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dv, scaler, X_train, X_val, X_test = pre_process_data(df_train, df_val, df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2faf3",
   "metadata": {},
   "source": [
    "## Resample train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ccd3838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y\n",
       "0    39910\n",
       "1     5286\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['y'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d60498e",
   "metadata": {},
   "source": [
    "So here our dataset is unbalnced dataset, To make it balanced dataset we should use `SMOTE` for training dataset only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "38a3d820",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_train_data(X_train, y_train):\n",
    "  \"\"\"\n",
    "  Apply SMOTE to balance the training data\n",
    "\n",
    "  Args:\n",
    "    X_train\n",
    "    y_train\n",
    "\n",
    "  Returns:\n",
    "    Tuple: containing the X_resampled, y_resampled\n",
    "  \"\"\"\n",
    "  smote = SMOTE(sampling_strategy=\"auto\", random_state=42)\n",
    "  X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "  return X_resampled, y_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f45f4b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_resampled, y_resampled = resample_train_data(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "83377375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smote is not working in notebook version, but its working into train.py file\n",
    "X_resampled = X_train\n",
    "y_resampled = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4135b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d434df8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_params_and_estimator(model_info, X_train, y_train, X_val, y_val):\n",
    "  \"\"\"\n",
    "  Get best hyperparameters and estimator by using GridSearchCV\n",
    "\n",
    "  Args:\n",
    "    model_info: Model information containing model name, model object, set of parameters\n",
    "    X_train: preprocessed training data set\n",
    "    y_train: training label\n",
    "    X_val: preprocessed validation data set\n",
    "    y_val: validation label\n",
    "\n",
    "  Returns:\n",
    "    Tuple: Tuple containing best hyper parameters and best estimators\n",
    "  \"\"\"\n",
    "  model = model_info['model']\n",
    "  model_name = model_info['name']\n",
    "  params = model_info.get('params', {})\n",
    "\n",
    "  grid_search = GridSearchCV(model, params, cv=5)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "  best_params = grid_search.best_params_\n",
    "  best_estimator = grid_search.best_estimator_\n",
    "  return best_params, best_estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "abb2678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_evaluation(model, X, y):\n",
    "  \"\"\"\n",
    "  Get model evaluation report, It helps us to understand how our model is behaving\n",
    "\n",
    "  Args:\n",
    "    model: Model on which we have to evaluate model accuracy\n",
    "    X: Dataset on which we will evaluate model accuracy\n",
    "    y: Actual label (Truth label values)\n",
    "  \"\"\"\n",
    "  y_pred = model.predict(X)\n",
    "  acc = roc_auc_score(y, y_pred)\n",
    "  return round(acc, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "14851332",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_reports(model_infos, X_train, y_train, X_val, y_val):\n",
    "  \"\"\"\n",
    "  Get the model report based on provided multiple model information\n",
    "\n",
    "  Args:\n",
    "    model_infos: Multiple model information\n",
    "    X_train, y_train: Training dataset\n",
    "    X_val, y_val: Validatioin dataset\n",
    "\n",
    "  Returns:\n",
    "    List: List of model reports containing, model name, model object, accuracy, hyperparameters\n",
    "  \"\"\"\n",
    "  model_reports = []\n",
    "  for model_info in model_infos:\n",
    "    best_params, best_estimator = get_best_params_and_estimator(model_info, X_train, y_train, X_val, y_val)\n",
    "    train_accuracy = get_model_evaluation(best_estimator, X_train, y_train)\n",
    "    val_accuracy = get_model_evaluation(best_estimator, X_val, y_val)\n",
    "    \n",
    "    print(f\"Model: {model_info['name']}, train_accuracy: {train_accuracy}, validation accuracy: {val_accuracy}\")\n",
    "    \n",
    "    model_report = {\n",
    "      \"name\": model_info[\"name\"],\n",
    "      \"model\": best_estimator,\n",
    "      \"best_params\": best_params,\n",
    "      \"train_accuracy\": train_accuracy,\n",
    "      \"val_accuracy\": val_accuracy\n",
    "    }\n",
    "    model_reports.append(model_report)\n",
    "\n",
    "  return model_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "70fa2952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LR, train_accuracy: 0.6484, validation accuracy: 0.6722\n",
      "Model: DecisionTreeClassifier, train_accuracy: 1.0, validation accuracy: 0.6934\n",
      "Model: RandomForestClassifier, train_accuracy: 1.0, validation accuracy: 0.6954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n",
      "/usr/local/anaconda3/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: XGBClassifier, train_accuracy: 0.7874, validation accuracy: 0.7162\n",
      "Model: LDA, train_accuracy: 0.6958, validation accuracy: 0.7173\n",
      "Model: NB, train_accuracy: 0.6956, validation accuracy: 0.6995\n"
     ]
    }
   ],
   "source": [
    "model_report = get_model_reports(model_infos, X_resampled, y_resampled, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "37550f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_info(model_reports):\n",
    "  \"\"\"\n",
    "  Get best model based on accuracy\n",
    "\n",
    "  Args:\n",
    "    model_report: List of model reports\n",
    "\n",
    "  Returns:\n",
    "    best_model: Best model based on model accuracy\n",
    "  \"\"\"\n",
    "  sorted_report = sorted(model_reports, key=lambda x: x['val_accuracy'], reverse=True)\n",
    "  return sorted_report[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4b46ced8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_info = get_best_model_info(model_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d1e34c4",
   "metadata": {},
   "source": [
    "### Save artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "374b14ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_artifacts(dictVectorizer, standardScaler, model, model_file):\n",
    "  \"\"\"\n",
    "  Save artifacts, that can be used in web server to generate prediction\n",
    "\n",
    "  Args:\n",
    "    dictVectorizer: One hot encoder\n",
    "    standardScaler: Standard Scaler\n",
    "    model: Best model\n",
    "    model_file: File name, in which model should be stored\n",
    "  \"\"\"\n",
    "  pipeline = make_pipeline(dictVectorizer, standardScaler, model)\n",
    "  with open(model_file,'wb') as f_out: \n",
    "    pickle.dump(pipeline, f_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3d3a290a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = best_model_info[\"model\"]\n",
    "save_artifacts(dv, scaler, best_model, artifact_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "dda8e7b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b313d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
